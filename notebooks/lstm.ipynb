{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from multiagent_rl.algos.agents import *\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operation of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1390, -0.2853]]], grad_fn=<StackBackward>)\n",
      "(tensor([[[-0.1390, -0.2853]]], grad_fn=<StackBackward>), tensor([[[-0.2345, -0.4600]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "input_dim = 3\n",
    "hidden_size = 2\n",
    "seq_len = 1\n",
    "lstm = nn.LSTM(input_dim, hidden_size)\n",
    "inputs = [torch.randn(1, input_dim) for _ in range(seq_len)]  # make a sequence of length seq_len\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, hidden_size),\n",
    "          torch.randn(1, 1, hidden_size))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, hidden_size), torch.randn(1, 1, hidden_size))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm object: LSTM(3, 2)\n",
      "input shape: torch.Size([1, 1, 3])\n",
      "out shape: torch.Size([1, 1, 2])\n",
      "hidden h shape: torch.Size([1, 1, 2])\n",
      "hidden c shape: torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'lstm object: {lstm}')\n",
    "print(f'input shape: {inputs.shape}')\n",
    "print(f'out shape: {out.shape}')\n",
    "print(f'hidden h shape: {hidden[0].shape}')\n",
    "print(f'hidden c shape: {hidden[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out tensor([[[-0.1390, -0.2853]]], grad_fn=<StackBackward>)\n",
      "h   tensor([[[-0.1390, -0.2853]]], grad_fn=<StackBackward>)\n",
      "c   tensor([[[-0.2345, -0.4600]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f'out {out}')\n",
    "print(f'h   {hidden[0]}')\n",
    "print(f'c   {hidden[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simple LSTM over multiple step input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_size = 2\n",
    "seq_len = 4\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "lstm = nn.LSTM(input_dim, hidden_size, num_layers)\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, hidden_size),\n",
    "          torch.randn(1, 1, hidden_size))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run an LSTM on a sequence of inputs:\n",
    "- generate input sequence of shape **(seq_len, batch, input_size)**\n",
    "- pass initial hidden state *(h)* of shape **(num_layers * num_directions, batch, hidden_size)**\n",
    "- pass initial cell state *(c)* of shape **(num_layers * num_directions, batch, hidden_size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:\n",
      " torch.Size([4, 1, 3])\n",
      "Input:\n",
      " tensor([[[ 1.0874, -0.5586,  0.3157]],\n",
      "\n",
      "        [[ 1.5174,  0.1300, -0.9286]],\n",
      "\n",
      "        [[-0.9993, -1.4282, -0.7373]],\n",
      "\n",
      "        [[-0.0306,  0.1277, -0.0047]]])\n"
     ]
    }
   ],
   "source": [
    "inputs = [torch.randn(1, input_dim) for _ in range(seq_len)]  # make a sequence of length seq_len\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "print(f'Input shape:\\n {inputs.shape}')\n",
    "print(f'Input:\\n {inputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden state shape:\n",
      " torch.Size([1, 1, 2])\n",
      "Initial hidden state:\n",
      " tensor([[[0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "h_0 = torch.zeros((num_layers, batch_size, hidden_size))\n",
    "c_0 = torch.zeros_like(h_0)\n",
    "print(f'Initial hidden state shape:\\n {h_0.shape}')\n",
    "print(f'Initial hidden state:\\n {h_0}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run input sequence(s) through LSTM, with initial hidden/cell states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (h_final, c_final) = lstm(inputs, (h_0, c_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden state shape:\n",
      " torch.Size([1, 1, 2])\n",
      "Final hidden state:\n",
      " tensor([[[ 0.0889, -0.1019]]], grad_fn=<StackBackward>)\n",
      "Final cell state shape:\n",
      " torch.Size([1, 1, 2])\n",
      "Final cell state:\n",
      " tensor([[[ 0.1639, -0.1388]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Final hidden state shape:\\n {h_final.shape}')\n",
    "print(f'Final hidden state:\\n {h_final}')\n",
    "print(f'Final cell state shape:\\n {c_final.shape}')\n",
    "print(f'Final cell state:\\n {c_final}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:\n",
      " torch.Size([4, 1, 2])\n",
      "Output:\n",
      " tensor([[[-0.0211, -0.2858]],\n",
      "\n",
      "        [[-0.0450, -0.2318]],\n",
      "\n",
      "        [[ 0.1083, -0.1997]],\n",
      "\n",
      "        [[ 0.0889, -0.1019]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Output shape:\\n {out.shape}')\n",
    "print(f'Output:\\n {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that final output is equal to final hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden state:\n",
      " tensor([[[ 0.0889, -0.1019]]], grad_fn=<StackBackward>)\n",
      "Last output:\n",
      " tensor([[ 0.0889, -0.1019]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Final hidden state:\\n {h_final}')\n",
    "print(f'Last output:\\n {out[-1,:,:]}')\n",
    "assert(torch.all(h_final.eq(out[-1,:,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run episode history through LSTM ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_size = 5\n",
    "action_size = 1\n",
    "low = 0\n",
    "high = 1\n",
    "actor = LSTMDeterministicActor(input_dim, hidden_size, action_size, low, high)\n",
    "critic = LSTMVEstimator(input_dim, hidden_size)\n",
    "actor_critic = LSTMJoinedActorCritic(input_dim, hidden_size, action_size, low, high)\n",
    "env_input = torch.randn(1, input_dim)\n",
    "# agent = RDPGAgent(env.observation_space, env.action_space, **agent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [[0.981526796499701, 0.06426801686601302, 0.081231609841804]] \n",
      "act tensor([[[0.6747]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.7026335258517828, 0.7316251786079838, 0.432987423020599]] \n",
      "act tensor([[[0.6720]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.27976755885431903, 0.5940676026565817, 0.6518292062113481]] \n",
      "act tensor([[[0.6611]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.9444828121876456, 0.25927251914765825, 0.3586612718481491]] \n",
      "act tensor([[[0.6692]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.5172339057534872, 0.9661745794135282, 0.9250493546548532]] \n",
      "act tensor([[[0.6590]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.8801894499513875, 0.9220330768524984, 0.3481792042224864]] \n",
      "act tensor([[[0.6682]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.08087023056326093, 0.04518220031705933, 0.37877875291441365]] \n",
      "act tensor([[[0.6591]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.8739606977901481, 0.5333578595490565, 0.8602360281654687]] \n",
      "act tensor([[[0.6591]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.03257078150877102, 0.9306844422288856, 0.06525237694461483]] \n",
      "act tensor([[[0.6622]]], grad_fn=<AddBackward0>)\n",
      "-----\n",
      "obs: [[0.017974467797118754, 0.956728373796735, 0.434690369539403]] \n",
      "act tensor([[[0.6561]]], grad_fn=<AddBackward0>)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "episode_length = 10\n",
    "for i in range(episode_length):\n",
    "    obs = [[np.random.rand() for j in range(input_dim)]]\n",
    "    print(f'obs: {obs} ')\n",
    "    act, _ = actor(torch.as_tensor(obs, dtype=torch.float32))\n",
    "#     act = agent.act(torch.as_tensor(obs, dtype=torch.float32), noise=True)\n",
    "    print(f'act {act}')\n",
    "    print('-----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_size = 5\n",
    "action_size = 1\n",
    "low = -10\n",
    "high = 20\n",
    "actor = LSTMDeterministicActor(input_dim, hidden_size, action_size, low, high)\n",
    "critic = LSTMVEstimator(input_dim, hidden_size)\n",
    "actor_critic = LSTMJoinedActorCritic(input_dim, hidden_size, action_size, low, high)\n",
    "env_input = torch.randn(1, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.7934]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[ 0.0568, -0.1332,  0.1781,  0.0766, -0.1196]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.1730, -0.2191,  0.3194,  0.1702, -0.2331]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "action_out, (h, c) = actor.forward(env_input)\n",
    "print(action_out)\n",
    "print(actor.h)\n",
    "print(actor.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1712]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[ 0.0683,  0.1675,  0.0892,  0.0398, -0.0290]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.1350,  0.2836,  0.2563,  0.1200, -0.0720]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "value, (h, c) = critic.forward(env_input)\n",
    "print(value)\n",
    "print(critic.h)\n",
    "print(critic.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.7177]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[0.2299]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[ 0.0683,  0.1675,  0.0892,  0.0398, -0.0290]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.1350,  0.2836,  0.2563,  0.1200, -0.0720]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "action_out, value, (h, c) = actor_critic.forward(env_input)\n",
    "print(action_out)\n",
    "print(value)\n",
    "print(critic.h)\n",
    "print(critic.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8419ac9c709a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPGLSTMAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/research/multiagent-rl/multiagent_rl/algos/agents.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obs_dim, obs_space, action_space, hidden_size, noise_std, pi_lr, q_lr, polyak, gamma, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobs_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mobs_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "agent = DDPGLSTMAgent(obs_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(layer_sizes, hidden_activation, final_activation, batchnorm=True):\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "        if i < len(layer_sizes) - 2:\n",
    "            # if batchnorm:\n",
    "            #     layers.append(nn.BatchNorm1d(layer_sizes[i + 1]))\n",
    "            layers.append(hidden_activation())\n",
    "        else:\n",
    "            layers.append(final_activation())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BoundedDeterministicActor(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP net for actor in bounded continuous action space.\n",
    "    Returns deterministic action.\n",
    "    Layer sizes passed as argument.\n",
    "    Input dimension: layer_sizes[0]\n",
    "    Output dimension: layer_sizes[-1] (should be 1 for V,Q)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, activation, low, high, **kwargs):\n",
    "        super().__init__()\n",
    "        self.low = torch.as_tensor(low)\n",
    "        self.width = torch.as_tensor(high - low)\n",
    "        self.net = mlp(layer_sizes, activation, nn.Tanh)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = (self.net(x) + 1) * self.width / 2 + self.low\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDualUltimatum(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, action_size, low, high):\n",
    "        super(LSTMDualUltimatum, self).__init__()\n",
    "        self.low = torch.as_tensor(low)\n",
    "        self.width = torch.as_tensor(high - low)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.action_size = action_size\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dimhidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)        \n",
    "        self.action_mlp = mlp([hidden_size, action_size], nn.Identity, nn.Tanh)\n",
    "\n",
    "    def forward(self, input, h=None, c=None):\n",
    "        if h is None: h=torch.zeros(self.hidden_size)\n",
    "        if c is None: c=torch.zeros(self.hidden_size)\n",
    "        lstm_out, (h, c) = self.lstm(input.view(len(input), 1, -1), (h,c))\n",
    "        x = self.action_mlp(lstm_out)\n",
    "        action_out = (x + 1) * self.width / 2 + self.low\n",
    "        return action_out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = 2\n",
    "input_size = 2\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "rnn_rl = nn.LSTM(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_rl = LSTMDualUltimatum(input_size, hidden_size, action_size, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.tensor([0.5, 0.5])\n",
    "action_input = action.view(1,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, (h,c) = rnn_rl(action_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    action, (h,c) = rnn_rl(action_input, (h,c))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm(i.view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See torch.nn.utils.rnn.pack_padded_sequence() or torch.nn.utils.rnn.pack_sequence() for details.\n",
    "\n",
    "h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "c_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    "\n",
    "If (h_0, c_0) is not provided, both h_0 and c_0 default to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].view(1, 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action.shape)\n",
    "print(action_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = rnn_rl(action_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_tanh = nn.Tanh()\n",
    "action_head = nn.Linear(hidden_size, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mlp = mlp([hidden_size, 1], nn.Identity, nn.Tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_head(out).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_tanh(action_head(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " m = nn.Tanh()\n",
    "input = torch.randn(2)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Tanh(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
